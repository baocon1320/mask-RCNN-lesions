{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip uninstall tensorflow --y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip uninstall tensorflow-gpu --y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tensorflow==1.14\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/baonguyen/LocalFiles/OnlineCourse/Practice/mask-RCNN/mask-rcnn/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/baonguyen/LocalFiles/OnlineCourse/Practice/mask-RCNN/mask-rcnn/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/baonguyen/LocalFiles/OnlineCourse/Practice/mask-RCNN/mask-rcnn/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/baonguyen/LocalFiles/OnlineCourse/Practice/mask-RCNN/mask-rcnn/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/baonguyen/LocalFiles/OnlineCourse/Practice/mask-RCNN/mask-rcnn/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/baonguyen/LocalFiles/OnlineCourse/Practice/mask-RCNN/mask-rcnn/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/baonguyen/LocalFiles/OnlineCourse/Practice/mask-RCNN/mask-rcnn/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/baonguyen/LocalFiles/OnlineCourse/Practice/mask-RCNN/mask-rcnn/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/baonguyen/LocalFiles/OnlineCourse/Practice/mask-RCNN/mask-rcnn/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/baonguyen/LocalFiles/OnlineCourse/Practice/mask-RCNN/mask-rcnn/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/baonguyen/LocalFiles/OnlineCourse/Practice/mask-RCNN/mask-rcnn/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/baonguyen/LocalFiles/OnlineCourse/Practice/mask-RCNN/mask-rcnn/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from imgaug import augmenters as iaa\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import model as modellib\n",
    "from mrcnn import visualize\n",
    "from mrcnn import utils\n",
    "from imutils import paths\n",
    "import numpy as np\n",
    "import argparse\n",
    "import imutils\n",
    "import random\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the dataset path, images path, and annotations file path\n",
    "DATASET_PATH = os.path.abspath(\"isic2018\")\n",
    "IMAGES_PATH = os.path.sep.join([DATASET_PATH, \"ISIC2018_Task1-2_Training_Input\"])\n",
    "MASKS_PATH = os.path.sep.join([DATASET_PATH, \"ISIC2018_Task1_Training_GroundTruth\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the amount of data to use for training\n",
    "TRAINING_SPLIT = 0.8\n",
    "IMAGE_PATHS = sorted(list(paths.list_images(IMAGES_PATH)))\n",
    "idxs = list(range(0, len(IMAGE_PATHS)))\n",
    "random.seed(42)\n",
    "random.shuffle(idxs)\n",
    "i = int(len(idxs) * TRAINING_SPLIT)\n",
    "trainIdxs = idxs[:i]\n",
    "valIdxs = idxs[i:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the class names dictionary\n",
    "CLASS_NAMES = {1: \"lesion\"}\n",
    "\n",
    "# initialize the path to the Mask R-CNN pre-trained on COCO\n",
    "COCO_PATH = \"mask_rcnn_coco.h5\"\n",
    "\n",
    "# initialize the name of the directory where logs and output model\n",
    "# snapshots will be stored\n",
    "LOGS_AND_MODEL_DIR = \"lesions_logs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LesionBoundaryConfig(Config):\n",
    "    # give the configuration a recognizable name\n",
    "    NAME = \"lesion\"\n",
    "\n",
    "    # set the number of GPUs to use training along with the number of\n",
    "    # images per GPU (which may have to be tuned depending on how\n",
    "    # much memory your GPU has)\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "    # set the number of steps per training epoch and validation cycle\n",
    "    STEPS_PER_EPOCH = len(trainIdxs) // (IMAGES_PER_GPU * GPU_COUNT)\n",
    "    VALIDATION_STEPS = len(valIdxs) // (IMAGES_PER_GPU * GPU_COUNT)\n",
    "\n",
    "    # number of classes (+1 for the background)\n",
    "    NUM_CLASSES = len(CLASS_NAMES) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LesionBoundaryInferenceConfig(LesionBoundaryConfig):\n",
    "    # set the number of GPUs and images per GPU (which may be\n",
    "    # different values than the ones used for training)\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "    # set the minimum detection confidence (used to prune out false\n",
    "    # positive detections)\n",
    "    DETECTION_MIN_CONFIDENCE = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LesionBoundaryDataset(utils.Dataset):\n",
    "    def __init__(self, imagePaths, classNames, width=1024):\n",
    "        # call the parent constructor\n",
    "        super().__init__(self)\n",
    "\n",
    "        # store the image paths and class names along with the width\n",
    "        # we’ll resize images to\n",
    "        self.imagePaths = imagePaths\n",
    "        self.classNames = classNames\n",
    "        self.width = width\n",
    "        \n",
    "    def load_lesions(self, idxs):\n",
    "        # loop over all class names and add each to the ’lesion’\n",
    "        # dataset\n",
    "        for (classID, label) in self.classNames.items():\n",
    "            self.add_class(\"lesion\", classID, label)\n",
    "\n",
    "        # loop over the image path indexes\n",
    "        for i in idxs:\n",
    "            # extract the image filename to serve as the unique\n",
    "            # image ID\n",
    "            imagePath = self.imagePaths[i]\n",
    "            filename = imagePath.split(os.path.sep)[-1]\n",
    "\n",
    "            # add the image to the dataset\n",
    "            self.add_image(\"lesion\", image_id=filename,\n",
    "            path=imagePath)\n",
    "            \n",
    "    def load_image(self, imageID):\n",
    "        # grab the image path, load it, and convert it from BGR to\n",
    "        # RGB color channel ordering\n",
    "        p = self.image_info[imageID][\"path\"]\n",
    "        image = cv2.imread(p)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # resize the image, preserving the aspect ratio\n",
    "        image = imutils.resize(image, width=self.width)\n",
    "\n",
    "        # return the image\n",
    "        return image\n",
    "\n",
    "    def load_mask(self, imageID):\n",
    "        # grab the image info and derive the full annotation path\n",
    "        # file path\n",
    "        info = self.image_info[imageID]\n",
    "        filename = info[\"id\"].split(\".\")[0]\n",
    "        annotPath = os.path.sep.join([MASKS_PATH,\n",
    "            \"{}_segmentation.png\".format(filename)])\n",
    "\n",
    "        # load the annotation mask and resize it, *making sure* to\n",
    "        # use nearest neighbor interpolation\n",
    "        annotMask = cv2.imread(annotPath)\n",
    "        annotMask = cv2.split(annotMask)[0]\n",
    "        annotMask = imutils.resize(annotMask, width=self.width,\n",
    "            inter=cv2.INTER_NEAREST)\n",
    "        annotMask[annotMask > 0] = 1\n",
    "\n",
    "        # determine the number of unique class labels in the mask\n",
    "        classIDs = np.unique(annotMask)\n",
    "\n",
    "        # the class ID with value '0' is actually the background\n",
    "        # which we should ignore and remove from the unique set of\n",
    "        # class identifiers\n",
    "        classIDs = np.delete(classIDs, [0])\n",
    "\n",
    "        # allocate memory for our [height, width, num_instances]\n",
    "        # array where each \"instance\" effectively has its own\n",
    "        # \"channel\" -- since there is only one lesion per image we\n",
    "        # know the number of instances is equal to 1\n",
    "        masks = np.zeros((annotMask.shape[0], annotMask.shape[1], 1),\n",
    "            dtype=\"uint8\")\n",
    "\n",
    "        # loop over the class IDs\n",
    "        for (i, classID) in enumerate(classIDs):\n",
    "            # construct a mask for *only* the current label\n",
    "            classMask = np.zeros(annotMask.shape, dtype=\"uint8\")\n",
    "            classMask[annotMask == classID] = 1\n",
    "\n",
    "        # store the class mask in the masks array\n",
    "        masks[:, :, i] = classMask\n",
    "\n",
    "        # return the mask array and class IDs\n",
    "        return (masks.astype(\"bool\"), classIDs.astype(\"int32\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/baonguyen/LocalFiles/OnlineCourse/Practice/mask-RCNN/mask-RCNN-lesions/isic2018/ISIC2018_Task1_Training_GroundTruthISIC_0000000_segmentation.png'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img1 = MASKS_PATH + 'ISIC_0000000_segmentation.png'\n",
    "img1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotMask = cv2.imread(img1)\n",
    "annotMask = cv2.split(annotMask)[0]\n",
    "annotMask = imutils.resize(annotMask, width=self.width,\n",
    "    inter=cv2.INTER_NEAREST)\n",
    "annotMask[annotMask > 0] = 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
